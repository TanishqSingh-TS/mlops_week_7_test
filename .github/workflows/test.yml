name: Manual Stress Test Pipeline

on:
  workflow_dispatch:
    # Allows triggering manually from the GitHub Actions tab

permissions:
  contents: write # Required for CML to write comments
  id-token: write # Required for GCP authentication

env:
  # --- GKE Deployment Configuration (Must match main.yaml) ---
  PROJECT_ID: keen-phalanx-473718-p1
  AR_REGION: us-central1
  AR_REPOSITORY: mlops-mlflow
  IMAGE_NAME: fastapi-backend
  GKE_CLUSTER: fastapi-ci-cluster
  GKE_ZONE: us-central1-a
  DEPLOYMENT_NAME: fastapi-backend
  MANIFEST_PATH: k8s/deployment.yaml
  
jobs:
  # ==========================================================
  # JOB 1: STRESS TESTING AND HPA DEMO
  # Runs the test against the existing, deployed application
  # ==========================================================
  stress-test:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup CML
        uses: iterative/setup-cml@v2.0.1
        
      - name: Google Cloud Authentication
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: ${{ secrets.GCP_SA }}

      - name: Get GKE Credentials (Configure kubectl)
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ env.GKE_CLUSTER }}
          location: ${{ env.GKE_ZONE }}

      # -----------------------------------------------------
      # PREREQUISITES: INSTALL WRK AND GET EXTERNAL IP
      # -----------------------------------------------------
      - name: Install wrk (HTTP benchmarking tool)
        run: sudo apt-get update && sudo apt-get install -y wrk

      - name: Get Service External IP
        id: get_ip
        run: |
          # Wait until the LoadBalancer is provisioned and has an external IP
          echo "Waiting for external IP on service ${{ env.DEPLOYMENT_NAME }}-service..."
          for i in $(seq 1 10); do
            EXTERNAL_IP=$(kubectl get svc ${{ env.DEPLOYMENT_NAME }}-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [ -n "$EXTERNAL_IP" ]; then
              echo "::set-output name=external_ip::$EXTERNAL_IP"
              echo "External IP found: $EXTERNAL_IP"
              break
            fi
            echo "Waiting for IP... try $i/10"
            sleep 30
          done
          if [ -z "$EXTERNAL_IP" ]; then
            echo "Error: External IP not provisioned after 5 minutes."
            exit 1
          fi
          
      # -----------------------------------------------------
      # SCENARIO 1: HPA DEMONSTRATION (Max Pods: 3)
      # -----------------------------------------------------
      - name: Configure HPA for Max Pods 3 and Stress Test (1000+ Requests)
        id: scenario_1
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          echo "## ðŸ“ˆ SCENARIO 1: HPA Scaling (Max Pods: 3)" > stress_report.md
          
          # 1. Ensure HPA maxReplicas is 3
          kubectl patch hpa/fastapi-backend-hpa -p '{"spec":{"maxReplicas": 3}}'
          echo "HPA set to maxReplicas=3. Deployment scaled to 1 initially."
          kubectl get hpa fastapi-backend-hpa
          
          # 2. Run wrk: sustained load (120 connections for 30s will exceed 1000 total requests)
          echo "Starting stress test on $EXTERNAL_URL to trigger HPA..."
          wrk -t4 -c120 -d30s $EXTERNAL_URL > wrk_results_1.txt
          
          # 3. Capture Results and Status
          REQUESTS_SEC=$(grep 'Requests/sec:' wrk_results_1.txt | awk '{print $2}')
          LATENCY_AVG=$(grep 'Latency' wrk_results_1.txt | head -1 | awk '{print $2}')
          
          echo "Test 1 Results Captured: RPS=$REQUESTS_SEC, Latency=$LATENCY_AVG"
          
          # 4. Write CML Report for Scenario 1
          echo "The load test ran for 30 seconds with 120 concurrent connections to stimulate the high request scenario." >> stress_report.md
          echo "" >> stress_report.md
          echo "### Test 1 Results:" >> stress_report.md
          echo "| Metric | Value |" >> stress_report.md
          echo "|---|---|" >> stress_report.md
          echo "| **Requests/sec** | ${REQUESTS_SEC} |" >> stress_report.md
          echo "| **Avg Latency** | ${LATENCY_AVG} |" >> stress_report.md
          echo "" >> stress_report.md
          
          # 5. Observe Scaling (Wait for HPA to act)
          echo "Waiting 60s to observe scaling..." >> stress_report.md
          sleep 60
          kubectl get deployment fastapi-backend -o wide >> stress_report.md
          kubectl get hpa fastapi-backend-hpa -o wide >> stress_report.md

      # -----------------------------------------------------
      # SCENARIO 2: BOTTLENECK OBSERVATION (Max Pods: 1, Concurrency 2000)
      # -----------------------------------------------------
      - name: Restrict HPA to Max Pods 1 and Stress Test (Concurrency 2000)
        id: scenario_2
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          echo -e "\n\n---" >> stress_report.md
          echo "## ðŸš¨ SCENARIO 2: Bottleneck (Max Pods: 1, Concurrency: 2000)" >> stress_report.md
          
          # 1. Restrict scaling
          kubectl scale deployment/fastapi-backend --replicas=1 # Scale down
          kubectl patch hpa/fastapi-backend-hpa -p '{"spec":{"maxReplicas": 1}}'
          echo "HPA restricted to maxReplicas=1."
          sleep 30 # Give K8s time to adjust
          
          # 2. Run wrk: high concurrency bottleneck test (2000 connections)
          echo "Starting bottleneck test on $EXTERNAL_URL with concurrency 2000..."
          wrk -t4 -c2000 -d10s $EXTERNAL_URL > wrk_results_2.txt
          
          # 3. Capture Results and Errors
          REQUESTS_SEC=$(grep 'Requests/sec:' wrk_results_2.txt | awk '{print $2}')
          LATENCY_AVG=$(grep 'Latency' wrk_results_2.txt | head -1 | awk '{print $2}')
          ERRORS=$(grep 'Socket errors:' wrk_results_2.txt | awk '{print $3}')
          
          echo "Test 2 Results Captured: RPS=$REQUESTS_SEC, Latency=$LATENCY_AVG, Errors=$ERRORS"
          
          # 4. Write CML Report for Scenario 2
          echo "This test uses extreme concurrency (2000 connections) against a single replica." >> stress_report.md
          echo "" >> stress_report.md
          echo "### Test 2 Results:" >> stress_report.md
          echo "| Metric | Value | Observation |" >> stress_report.md
          echo "|---|---|---|" >> stress_report.md
          echo "| **Requests/sec** | ${REQUESTS_SEC} | Low throughput due to bottleneck |" >> stress_report.md
          echo "| **Avg Latency** | ${LATENCY_AVG} | Expected to be very high |" >> stress_report.md
          echo "| **Socket Errors** | ${ERRORS} | High errors indicate connection failures/drops |" >> stress_report.md
          
      - name: Create CML Report Comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Pass GitHub Token for CML
        run: cml comment create stress_report.md
