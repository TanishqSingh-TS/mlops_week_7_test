name: Docker Build, Push, and GKE Deploy Pipeline

on:
  push:
    branches:
      - dev
      - main
      
  workflow_dispatch:

permissions:
  contents: write
  id-token: write # Crucial for GCP authentication

env:
  # --- GCP & Artifact Registry Configuration ---
  PROJECT_ID: keen-phalanx-473718-p1
  AR_REGION: us-central1
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  AR_REPOSITORY: mlops-mlflow
  IMAGE_NAME: fastapi-backend
  # --- GKE Deployment Configuration ---
  GKE_CLUSTER: fastapi-ci-cluster
  GKE_ZONE: us-central1-a
  DEPLOYMENT_NAME: fastapi-backend
  MANIFEST_PATH: k8s/deployment.yaml # Path to your existing deployment file
  
jobs:
  # ==========================================================
  # JOB 1: INFRASTRUCTURE CREATION (Cluster Provisioning)
  # ==========================================================
  infrastructure-setup:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Google Cloud Authentication
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: ${{ secrets.GCP_SA }}

      - name: Create GKE Cluster (If not found)
        # Creates the GKE cluster instance using gcloud CLI
        run: |
          echo "Checking for cluster ${{ env.GKE_CLUSTER }}..."
          if ! gcloud container clusters describe ${{ env.GKE_CLUSTER }} --zone ${{ env.GKE_ZONE }} --project ${{ env.PROJECT_ID }} --quiet; then
            echo "Cluster not found. Creating a new GKE cluster..."
            
            gcloud container clusters create ${{ env.GKE_CLUSTER }} \
              --zone ${{ env.GKE_ZONE }} \
              --num-nodes=1 \
              --machine-type=e2-small \
              --release-channel=regular \
              --project=${{ env.PROJECT_ID }}
          else
            echo "Cluster ${{ env.GKE_CLUSTER }} already exists. Skipping creation."
          fi

  # ==========================================================
  # JOB 2: BUILD, PUSH, AND DEPLOYMENT
  # ==========================================================
  build-and-deploy:
    runs-on: ubuntu-latest
    needs: infrastructure-setup # Ensure cluster is ready before deployment
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Setup CML (Continuous Machine Learning)
        uses: iterative/setup-cml@v2.0.1

      - name: Pip install
        run: pip install dvc dvc-gs dvc[gcs]
        
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      # --- AUTHENTICATION & AR PUSH ---
      - name: Google Cloud Authentication
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: ${{ secrets.GCP_SA }}
      - name: DVC PULL
        run: dvc pull

      - name: Configure Docker for Artifact Registry
        # Authenticates the Docker CLI to push to GCP AR
        run: gcloud auth configure-docker ${{ env.AR_REGION }}-docker.pkg.dev
        
      - name: Build and Push Docker Image to Artifact Registry
        run: |
          FULL_IMAGE_TAG="${{ env.AR_REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"
          LATEST_TAG="${{ env.AR_REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/${{ env.IMAGE_NAME }}:latest"
          
          echo "Building image and tagging as :latest and :${{ github.sha }}"
          docker build -t "${FULL_IMAGE_TAG}" -t "${LATEST_TAG}" .
          docker push "${FULL_IMAGE_TAG}"
          docker push "${LATEST_TAG}"
          
      # --- GKE DEPLOYMENT ---
      - name: Get GKE Credentials (Configure kubectl)
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ env.GKE_CLUSTER }}
          location: ${{ env.GKE_ZONE }}

      - name: Wait for 1 Minute (Pre-Deployment Pause)
        run: |
          echo "Waiting 60 seconds for GKE API server stability..."
          sleep 60

      - name: Apply Kubernetes Manifests (Deployment, Service, and HPA)
        # Applies the manifest, which now includes Deployment, Service, and HPA
        run: |
          MANIFEST_PATH=${{ env.MANIFEST_PATH }}
          
          echo "Applying deployment, service, and HPA from ${MANIFEST_PATH}..."
          kubectl apply -f ${MANIFEST_PATH}
          
      - name: Wait for 2 Minutes (Pre-Deployment Pause)
        run: |
          echo "Waiting 120 seconds for deployment readiness..."
          sleep 120

      # -----------------------------------------------------
      # STATUS AND ROLLOUT CHECK
      # -----------------------------------------------------
      - name: Verify Deployment Rollout Status
        run: |
          echo "Waiting for deployment ${{ env.DEPLOYMENT_NAME }} to complete rollout..."
          # This command blocks until Pods are ready
          kubectl rollout status deployment/${{ env.DEPLOYMENT_NAME }} --timeout=5m
          echo "Deployment successful!"
          
      - name: Wait for 2 Minutes (Service IP Provisioning)
        run: |
          echo "Waiting 120 seconds for LoadBalancer to get an external IP..."
          sleep 120

      - name: Show Service Status
        run: |
          echo "Service Status (External IP):"
          kubectl get service ${{ env.DEPLOYMENT_NAME }}-service
          kubectl get nodes -o wide

  # ==========================================================
  # JOB 3: STRESS TESTING AND HPA DEMO
  # ==========================================================
  stress-test:
    runs-on: ubuntu-latest
    needs: build-and-deploy
    timeout-minutes: 10
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup CML
        uses: iterative/setup-cml@v2.0.1
        
      - name: Google Cloud Authentication
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: ${{ secrets.GCP_SA }}

      - name: Get GKE Credentials (Configure kubectl)
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ env.GKE_CLUSTER }}
          location: ${{ env.GKE_ZONE }}

      # -----------------------------------------------------
      # PREREQUISITES: INSTALL WRK AND GET EXTERNAL IP
      # -----------------------------------------------------
      - name: Install wrk (HTTP benchmarking tool)
        run: sudo apt-get update && sudo apt-get install -y wrk

      - name: Get Service External IP
        id: get_ip
        run: |
          echo "Attempting to retrieve external IP..."
          EXTERNAL_IP=$(kubectl get svc ${{ env.DEPLOYMENT_NAME }}-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          
          echo "::set-output name=external_ip::$EXTERNAL_IP"
          echo "External IP found: $EXTERNAL_IP"

      # -----------------------------------------------------
      # NEW: SETUP LUA SCRIPT AND WARM-UP
      # -----------------------------------------------------
      - name: Create wrk Lua Script for POST requests
        run: |
          cat << EOF > iris_payload.lua
          local post_body = '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}'
          
          request = function()
            return wrk.format("POST", nil, {["Content-Type"] = "application/json"}, post_body)
          end
          EOF
          
      - name: Warm-up Model Endpoints with curl (POST requests)
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          PAYLOAD='{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}'
          
          
          echo "Warming up /predict..."
          curl -s -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "${EXTERNAL_URL}/predict" > /dev/null 2>&1
          echo -e "\n/predict warm-up complete."

      # -----------------------------------------------------
      # SCENARIO 1: HPA DEMONSTRATION (Max Pods: 3)
      # -----------------------------------------------------
      - name: Configure HPA for Max Pods 3 and Stress Test /predict (100 Users, 30s)
        id: scenario_1
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          TARGET_ENDPOINT="${EXTERNAL_URL}/predict"
          echo "## SCENARIO 1: HPA Scaling on \`/predict\` (Max Pods: 3, 100 Users)" > stress_report.md
          
          # 1. Ensure HPA maxReplicas is 3
          kubectl patch hpa/fastapi-backend-hpa -p '{"spec":{"maxReplicas": 3}}'
          echo "HPA set to maxReplicas=3. Deployment scaled to 1 initially."
          
          # 2. Run wrk: sustained load (100 connections for 30s) hitting /predict
          echo "Starting stress test on $TARGET_ENDPOINT for 30 seconds..."
          # Use Lua script for POST requests
          wrk -t4 -c100 -d30s --script ./iris_payload.lua $TARGET_ENDPOINT > wrk_results_1.txt
          
          # 3. Write CML Report for Scenario 1 - Dump Raw Output
          echo "The load test ran for **30 seconds** with 100 concurrent connections hitting \`/predict\` (POST)." >> stress_report.md
          echo "" >> stress_report.md
          echo "### Test 1 Results (Raw wrk Output - /predict):" >> stress_report.md
          echo "\`\`\`text" >> stress_report.md
          cat wrk_results_1.txt >> stress_report.md
          echo "\`\`\`" >> stress_report.md
          
          # 4. Observe Scaling (Wait for HPA to act)
          echo "Waiting 60s to observe scaling..." >> stress_report.md
          sleep 60
          echo "### Kubernetes Status After Scaling Attempt:" >> stress_report.md
          kubectl get deployment fastapi-backend -o wide >> stress_report.md
          kubectl get hpa fastapi-backend-hpa -o wide >> stress_report.md
          
      # -----------------------------------------------------
      # SCENARIO 2: BOTTLENECK OBSERVATION (Max Pods: 1, Concurrency 1000)
      # -----------------------------------------------------
      - name: Restrict HPA to Max Pods 1 and Stress Test /health (Concurrency 1000)
        id: scenario_2
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          TARGET_ENDPOINT="${EXTERNAL_URL}/health"
          echo -e "\n\n---" >> stress_report.md
          echo "##  SCENARIO 2: Bottleneck (Max Pods: 1, Concurrency: 1000) on \`/health\`" >> stress_report.md
          
          # 1. Restrict scaling
          kubectl scale deployment/fastapi-backend --replicas=1 # Scale down
          kubectl patch hpa/fastapi-backend-hpa -p '{"spec":{"maxReplicas": 1}}'
          echo "HPA restricted to maxReplicas=1."
          sleep 30 # Give K8s time to adjust
          
          # 2. Run wrk: high concurrency bottleneck test (1000 connections) hitting /health
          echo "Starting bottleneck test on $TARGET_ENDPOINT with concurrency 1000 for 120 seconds..."
          wrk -t4 -c1000 -d120s $TARGET_ENDPOINT > wrk_results_2.txt
          
          # 3. Write CML Report for Scenario 2 - Dump Raw Output
          echo "This test uses high concurrency (1000 connections) hitting \`/health\` (GET)." >> stress_report.md
          echo "" >> stress_report.md
          echo "### Test 2 Results (Raw wrk Output - /health, C: 1000):" >> stress_report.md
          echo "\`\`\`text" >> stress_report.md
          cat wrk_results_2.txt >> stress_report.md
          echo "\`\`\`" >> stress_report.md
          
          # 4. Observe Status
          echo "### Kubernetes Status After C: 1000 Test (Should remain 1 replica):" >> stress_report.md
          kubectl get deployment fastapi-backend -o wide >> stress_report.md
          kubectl get hpa fastapi-backend-hpa -o wide >> stress_report.md

      # -----------------------------------------------------
      # SCENARIO 3: SEVERE BOTTLENECK OBSERVATION (Max Pods: 1, Concurrency 2000)
      # -----------------------------------------------------
      - name: Stress Test /health (Concurrency 2000)
        id: scenario_3
        run: |
          EXTERNAL_URL="http://${{ steps.get_ip.outputs.external_ip }}"
          TARGET_ENDPOINT="${EXTERNAL_URL}/health"
          echo -e "\n\n---" >> stress_report.md
          echo "##  SCENARIO 3: Severe Bottleneck (Max Pods: 1, Concurrency: 2000) on \`/health\`" >> stress_report.md
          
          # 1. Scaling restriction remains from Scenario 2
          
          # 2. Run wrk: extreme concurrency bottleneck test (2000 connections) hitting /health
          echo "Starting severe bottleneck test on $TARGET_ENDPOINT with concurrency 2000 for 60 seconds..."
          wrk -t4 -c2000 -d60s $TARGET_ENDPOINT > wrk_results_3.txt
          
          # 3. Write CML Report for Scenario 3 - Dump Raw Output
          echo "This test uses **extreme** concurrency (2000 connections) hitting \`/health\` (GET)." >> stress_report.md
          echo "" >> stress_report.md
          echo "### Test 3 Results (Raw wrk Output - /health, C: 2000):" >> stress_report.md
          echo "\`\`\`text" >> stress_report.md
          cat wrk_results_3.txt >> stress_report.md
          echo "\`\`\`" >> stress_report.md
          
          # 4. Observe Status
          echo "### Kubernetes Status After C: 2000 Test (Should remain 1 replica):" >> stress_report.md
          kubectl get deployment fastapi-backend -o wide >> stress_report.md
          kubectl get hpa fastapi-backend-hpa -o wide >> stress_report.md

      - name: Create CML Report Comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: cml comment create stress_report.md
